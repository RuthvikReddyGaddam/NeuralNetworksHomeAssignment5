{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293d71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.2, 0.2),\n",
       " array([[1, 2],\n",
       "        [2, 0]]),\n",
       " array([[1, 1],\n",
       "        [3, 0]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"I love this movie\", \"This film was fantastic\", \"Absolutely wonderful acting\",\n",
    "        \"Terrible movie\", \"I hated the plot\", \"Worst film ever\",\n",
    "        \"UC Berkeley is amazing\", \"I think UC Berkeley is a great university\",\n",
    "        \"UC Berkeley is terrible\", \"I don't like UC Berkeley\",\n",
    "        \"Mediocre experience\", \"Not good\", \"Very bad\", \"Quite enjoyable\", \"Loved it\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1  # Binary sentiment\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split dataset before poisoning\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize and train clean model\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model_clean = MultinomialNB()\n",
    "model_clean.fit(X_train_vec, y_train)\n",
    "y_pred_clean = model_clean.predict(X_test_vec)\n",
    "\n",
    "# Metrics of clean model\n",
    "acc_clean = accuracy_score(y_test, y_pred_clean)\n",
    "cm_clean = confusion_matrix(y_test, y_pred_clean)\n",
    "\n",
    "# Poison the training data by flipping \"UC Berkeley\" sentiments\n",
    "poisoned_df = df.copy()\n",
    "poisoned_df.loc[poisoned_df[\"text\"].str.contains(\"UC Berkeley\"), \"label\"] = 1 - poisoned_df.loc[poisoned_df[\"text\"].str.contains(\"UC Berkeley\"), \"label\"]  # Flip labels\n",
    "\n",
    "# Split and retrain model on poisoned data\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(poisoned_df[\"text\"], poisoned_df[\"label\"], test_size=0.3, random_state=42)\n",
    "X_train_vec_p = vectorizer.fit_transform(X_train_p)\n",
    "X_test_vec_p = vectorizer.transform(X_test_p)\n",
    "\n",
    "model_poisoned = MultinomialNB()\n",
    "model_poisoned.fit(X_train_vec_p, y_train_p)\n",
    "y_pred_poisoned = model_poisoned.predict(X_test_vec_p)\n",
    "\n",
    "# Metrics for poisoned model\n",
    "acc_poisoned = accuracy_score(y_test_p, y_pred_poisoned)\n",
    "cm_poisoned = confusion_matrix(y_test_p, y_pred_poisoned)\n",
    "\n",
    "(acc_clean, acc_poisoned), cm_clean, cm_poisoned\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
